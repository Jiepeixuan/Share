##Java
### 1.多线程
#### 1.1 进程状态
![多线程详细](./img/thread.png)<br/>

> **1.NEW(新建尚未运行/启动)**
>
> 还没调用start，或者调用了start()方法，不一定立即改变线程状态，中间可能需要一些步骤才完成一个线程的启动。
>
> **2.RUNNABLE(处于可运行状态：正在运行或准备运行)**
> 
> start调用结束，线程由NEW变成RUNNABLE，存活着，并尝试占用CPU资源，yield操作时，线程还是RUNNABLE状态，只是它有一个细节的内部变化，做一个简单的让步。在Java层面是RUNNABLE的状态，并不代表一定处于运行中的状态，比如BIO中，线程正阻塞在网络等待的时候，看到的状态依然是RUNNABLE状态，而底层线程已经被阻塞住了。
>
> **3.BLOCKED(等待获取锁时进入的状态)** 
> 线程被挂起了，原因通常是因为它在等待一个锁，当某个**synchronized**正好有线程在使用时，一个线程尝试进入这个临界区，就会被阻塞，直到另一个线程走完临界区或发生了相应锁对象的wait操作后，它才有机会去争夺进入临界区的权利。当抢到锁之后，才会从BLOCKED状态恢复到RUNNABLE状态。这个状态它好像什么也不做一样。
>
> **4.WAITING(通过wait方法进入的等待)** 
>
>当wait，join，park方法调用时，进入waiting状态。前提是这个线程已经拥有锁了。
>
>>BLOCKED和WAITING状态的区别是：
>
>>A、blocked是虚拟机认为程序还不能进入某个区域，因为同时进去就会有问题，这是一块临界区。
>>B、发生wait等操作的先决条件是要进入临界区，也就是线程已经拿到锁了，自己可能进去做了一些事情，但此时通过判定业务上的参数，发现还有一些其他配合的资源没有准备充分，那么自己就等等再做其他事情。

>在WAITING状态下，如果发生了interrupt操作，则处于该状态的线程在内部会抛出一个InterruptedException，这个异常应当在run方法内捕获，使得run方法正常地执行完成，当然捕获异常后，是决定让线程继续运行，还是结束等要根据业务场景才处理。如果发生了notify动作，则会从等待池当中唤醒一个线程重新恢复到Runnable状态，如果是notifyall操作，则唤醒所有等待线程。 
>
> **5.TIMED_WAITING(通过sleep或wait timeout方法进入的限期等待的状态)**
> 
> 通过wait(t),sleep(t),join(t),parkNanos,parkUntil等方法进入此状态。当时间达到时触发线程回到工作状态Runnable。interrupt只对处于waiting或timed_waiting状态的线程起作用，对其他状态不起作用。 
>
> **6.TERMINATED(线程终止状态)**
> 
> 线程结束了，就处于这种状态，也就是run方法运行完了。这只是Java语言级别的一种状态，在操作系统内部可能已经注销了相应的线程，或者将它复用给其他需要使用线程的请求。


#### 1.2 开启线程的三种方式
     1.新建类继承 Thread 类实现线程

     2.通过实现接口 Runnable 实现创建线程

     3.使用 Callable、ExecutionException、ExecutorService、Future 等类，Executors 框架实现线程，此方法：相对前两种可抛异常，且有返回值。

>    **说明**：前两种主要是通过继承线程类或实现接口，来实现 run() 方法，线程对象调用 start() 方法启动线程
#### 1.3 run()和start()方法区别
   
    start() : 它的作用是启动一个新线程，新线程会执行相应的run()方法。start()不能被重复调用。

    run() : run()就和普通的成员方法一样，可以被重复调用。单独调用run()的话，会在当前线程中执行run()，而并不会启动新线程！
#### 1.4sleep/wait/notify
>    sleep()方法是Thread类中方法，而wait()方法是Object类中的方法。
    
>    sleep()方法导致了程序暂停执行指定的时间，让出cpu该其他线程，但是他的监控状态依然保持者，当指定的时间到了又会自动恢复运行状态，在调用sleep()方法的过程中，线程不会释放对象锁。
    
>    当调用wait()方法的时候，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象调用notify()方法后本线程才进入对象锁定池准备 

#### 1.5Java线程池

#### 1.6synchronized与Lock的区别、synchronized用法
>主要相同点：Lock能完成synchronized所实现的所有功能
    
>主要不同点：Lock有比synchronized更精确的线程语义和更好的性能。Lock的锁定是通过代码实现的，而synchronized是在JVM层面上实现的，synchronized会自动释放锁，而Lock一定要求程序员手工释放，并且必须在finally从句中释放。Lock还有更强大的功能，例如，它的tryLock方法可以非阻塞方式去拿锁。Lock锁的范围有局限性，块范围，而synchronized可以锁住块、对象、类。

#### 1.7并发特性
>**1.原子性**
>
>     即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行
>在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。
>上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子i：

>请分析以下哪些操作是原子性操作：
>
>     x = 10;         //语句1
>
>     y = x;         //语句2
>
>     x++;           //语句3
>
>     x = x + 1;     //语句4
>     
>咋一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。

>语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。

>语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。

>同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。

>所以上面4个语句只有语句1的操作具备原子性。

>也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。

>不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。

>从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。

>**2.可见性**
>
>     可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。于可见性，Java提供了volatile关键字来保证可见性。

>volatile保证可见性的原理是在每次 访问变量时都会进行一次刷新，因此每次访问都是主内存中最新的版本。
　　当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。

>而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。

>另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。



>**3.有序性**

>     即程序执行的顺序按照代码的先后顺序执行。

>指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，
它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终
执行结果和代码顺序执行的结果是一致的。

#### 1.8volatile的原理</br>

>**可见性实现**

>线程本身并不直接与主内存进行数据的交互，而是通过线程的工作内存来完成相应的操作。这也是导致线程间数据不可见的本质原因。因此要实现volatile变量的可见性，直接从这方面入手即可。对volatile变量的写操作与普通变量的主要区别有两点：

>(1)修改volatile变量时会强制将修改后的值刷新的主内存中。

>(2)修改volatile变量后会导致其他线程工作内存中对应的变量值失效。因此，再读取该变量值的时候就需要重新从读取主内存中的值。

>通过这两个操作，就可以解决volatile变量的可见性问题。

#### 1.9synchronize的原理</br>
#### 1.10lock原理</br>

>Lock与synchronized的区别

>1. Lock的加锁和解锁都是由java代码配合native方法（调用操作系统的相关方法）实现的，而synchronize的加锁和解锁的过程是由JVM管理的

>2. 当一个线程使用synchronize获取锁时，若锁被其他线程占用着，那么当前只能被阻塞，直到成功获取锁。而Lock则提供超时锁和可中断等更加灵活的方式，在未能获取锁的     条件下提供一种退出的机制。

>3. 一个锁内部可以有多个Condition实例，即有多路条件队列，而synchronize只有一路条件队列；同样Condition也提供灵活的阻塞方式，在未获得通知之前可以通过中断线程以    及设置等待时限等方式退出条件队列。

>4. synchronize对线程的同步仅提供独占模式，而Lock即可以提供独占模式，也可以提供共享模式

#### 1.11volatile用法

     1.防止重排序
     2.实现可见性
     3.保证原子性
#### 1.12进程与线程
#### 1.13死锁

>死锁，是指多个进程循环等待它方占有的资源而无限期地僵持下去的局面。很显然，如果没有外力的作用，那麽死锁涉及到的各个进程都将永远处于封锁状态。
    
>只要下面四个条件有一个不具备，系统就不会出现死锁。
>
>>**〈1〉互斥条件**
>> 
>> 即某个资源在一段时间内只能由一个进程占有，不能同时被两个或两个以上的进程占有。这种独占资源如CD-ROM驱动器，打印机等等，必须在占有该资源的进程主动释放它之后，其它进程才能占有该资源。这是由资源本身的属性所决定的。如独木桥就是一种独占资源，两方的人不能同时过桥。
> 
>> **〈2〉不可抢占条件**
>> 
>> 进程所获得的资源在未使用输入代完毕之前，资源申请者不能强行地从资源占有者手中夺取资源，而只能由该资源的占有者进程自行释放。如过独木桥的人不能强迫对方后退，也不能非法地将对方推下桥，必须是桥上的人自己过桥后空出桥面（即主动释放占有资源），对方的人才能过桥。
    
>> **〈3〉占有且申请条件**
>> 
>> 进程至少已经占有一个资源，但又申请新的资源；由于该资源已被另外进程占有，此时该进程阻塞；但是，它在等待新资源之时，仍继续占用已占有的资源。还以过独木桥为例，甲乙两人在桥上相遇。甲走过一段桥面（即占有了一些资源），还需要走其余的桥面（申请新的资源），但那部分桥面被乙占有（乙走过一段桥面）。甲过不去，前进不能，又不后退；乙也处于同样的状况。
> 
>>**〈4〉循环等待条件**
>>
>>存在一个进程等待序列{P1，P2，...，Pn}，其中P1等待P2所占有的某一资源，P2等待P3所占有的某一源，......，而Pn等待P1所占有的的某一资源，形成一个进程循环等待环。就像前面的过独木桥问题，甲等待乙占有的桥面，而乙又等待甲占有的桥面，从而彼此循环等待。
  上面我们提到的这四个条件在死锁时会同时发生。也就是说，只要有一个必要条件不满足，则死锁就可以排除。

#### 1.14ReentrantLock
#### 1.15并发集合了解哪些
#### 1.16CAS介绍

>Compare and Swap, **比较并交换**。
>
> java.util.concurrent包中借助CAS实现了区别于synchronouse同步锁的一种乐观锁。
CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。

>**缺点**

>***ABA 问题***

>由于 CAS 设计机制就是获取某两个时刻(初始预期值和当前内存值)变量值，并进行比较更新，所以说如果在获取初始预期值和当前内存值这段时间间隔内，变量值由 A 变为 B 再变为 A，那么对于 CAS 来说是不可感知的，但实际上变量已经发生了变化；解决办法是在每次获取时加版本号，并且每次更新对版本号 +1，这样当发生 ABA 问题时通过版本号可以得知变量被改动过

>JDK 1.5 以后的 AtomicStampedReference 类就提供了此种能力，其中的 compareAndSet 方法就是 首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

>***循环时间长开销大***

>所谓循环时间长开销大问题就是当 CAS 判定变量被修改了以后则放弃本次修改，但往往为了保证数据正确性该计算会以循环的方式再次发起 CAS，如果多次 CAS 判定失败，则会产生大量的时间消耗和性能浪费；如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。

>***只能保证一个共享变量的原子操作***

>CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效；从 JDK 1.5开始提供了 AtomicReference 类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作


#### 1.17如何保证多线程读写文件的安全
#### 1.18如何保证线程安全
### 2JVM
#### 2.1运行时区域内存
![JVm运行时内存分配](./img/JVM_runtime.png)<br/>

>####1 . 程序计数器

>**(1)含义作用**

> 程序计数器（Program Counter Register）是一块较小的内存空间，可以看作是**当前线程**所执行的字节码的行号指示器。在虚拟机概念模型中，字节码解释器工作时就是通过改变计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖计数器。

>**(2)计数器与多线程**

>由于JVM的多线程时通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）都只会执行一条线程中的指令。所以，为了线程切换后能恢复到正确的执行位置，每条线程需要一个独立的程序计数器，各线程之间计数器互不影响、独立存储，相当于是一块“线程私有”的内存。

>**虚拟机规范记录（有关异常）**

>若线程正在执行的是一个Java方法，这个计数器记录的时正在执行的虚拟机字节码指令的地址；若执行的是Native方法，则计数器为空（Undefined）。注意：此内存区域是唯一一个在Java虚拟机规范中没有规定任何 OutOfMemoryError情况的区域。

>####2.Java虚拟机栈

>**(1)含义作用**

>同程序计数器相同，**Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同**。虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，会对应一个栈帧在虚拟机栈中入栈到出栈的过程。

>**(2)Java内存区分误区**

>大多数人以为Java内存区分为堆内存（Heap）和栈内存（Stack），这是一种误区，Java内存区域的划分远比这种粗糙的分法更加复杂。这种划分方式广泛流传是由于大多数开发者关注与对象内存分配关系最密切的内存区域就是这两块，有关“堆”的知识后续载提，这里的“栈”指的就是虚拟机栈，或者说是虚拟机栈中的变量表部分。

>**(3)虚拟机栈中的局部变量表**

>局部变量表中存放了编译期可知的

>八大数据类型（boolean、byte、char、short、int、float、long、double）。

>对象引用（reference类型，它不等于对象本身，可能是一个指向对象起始地址的指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）

>returnAddress类型（指向了一条字节码指令的地址）

>其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余数据类型只占用1个。局部变量表所需的内存控件在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。

>**(4)虚拟机规范记录（有关异常）**

>在Java虚拟机规范中，对这个区域规定了两种异常状况：

>若线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常。
若虚拟机可以动态扩展（当前大部分Java虚拟机都可动态扩展，只不过Java虚拟机规范也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。

>**3.本地方法栈**

>(1)含义作用

>本地方法栈（Native Method Stack）与虚拟机栈所发挥的作用类似，它们之间的区别是：虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。

>(2)虚拟机规范记录（有关异常）

>在虚拟机规范中对本地方法栈中使用的语言、方式和数据结构并无强制规定，因此具体的虚拟机可实现它。甚至有的虚拟机（Sun HotSpot虚拟机）直接把本地方法栈和虚拟机栈合二为一。

>与虚拟机一样，本地方法栈会抛出StackOverflowError和OutOfMemoryError异常。

>**4.Java堆**

>(1)含义作用

>对于大多数应用而言，Java堆（Heap）是Java虚拟机所管理的内存中最大的一块，它是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域唯一的目的是存放对象实例，几乎所有的对象实例都在这里分配内存。Java虚拟机规范中描述道：所有的对象实例以及数组都要在堆上分配，但是随着JIT编译器的发展和逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化发生，所有的对象都在堆上分配的定论也并不“绝对”了。

>(2)Java堆与垃圾回收器

>Java堆是垃圾回收器管理的主要区域，因此被称为“GC堆”（Garbage Collected Heap）。

>从内存回收角度看，由于目前收集器基本采用分代收集算法，所以Java堆可细分为：新生代和老年代。

>从内存分配角度来看，线程共享的Java堆中可能划分出多个线程私有的分配缓冲区（TLAB：Thread Local Allocation Buffer）。


>(3)虚拟机规范记录（有关异常）

>根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存中，只要逻辑上是连续的即可，就像磁盘空间。在实现时，可以实现成固定大小或可扩展的，不过当前主流虚拟机是按照可扩展进行实现的（通过-Xmx和 -Xms控制）。

>若堆中没有内存完成实例分配，并且堆也无法扩展时，将会抛出OutOfMemoryError异常。

>**5.方法区**

>(1)含义作用

>方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它有一个别名叫做 Non-Heap（非堆），目的是为了和Java堆区分开来。

>(2)虚拟机规范记录（有关异常）

>Java虚拟机规范对方法区的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域比较少见。此区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说，回收效果难以令人满意，尤其是类型的卸载，条件相对苛刻，但是这部分区域回收是有必要的。

>根据Java虚拟机规范的规定，当方法无法满足内存需求时，将会抛出OutOfMemoryError异常。

>**6.运行时常量池**

>(1)含义作用

>运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池（Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池存放。

>(2)运行时常量池和Class文件

>Java虚拟机对Class文件每一部分（自然包括常量池）的格式有严格规定，每一个字节用于存储那种数据都必须符合规范上的要求才会被虚拟机认可、装载和执行。但对于运行时常量池，Java虚拟机规范没有做任何有关细节的要求，不同的提供商实现的虚拟机可以按照自己的需求来实现此内存区域。不过一般而言，除了保存Class文件中的描述符号引用外，还会把翻译出的直接引用也存储在运行时常量池中。

>运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，Java语言并不要求常量一定只有编译器才能产生，也就是并非置入Class文件中的常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，此特性被开发人员利用得比较多的便是String类的intern() 方法。

>(3)**虚拟机规范记录（有关异常）**

>运行时常量池是方法区的一部分，自然受到方法区的内存限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。

>**7.直接内存**

>(1)含义作用

>直接内存（Direct Memory）并不是虚拟机运行时数据的一部分，也不是Java虚拟机规范中定义的内存区域。但这部分内存也被频繁运用，而却可能导致OutOfMemoryError异常出现。

>(2)有关异常

>本机直接内存的分配不会受到Java堆大小的限制，但是既然是内存，还是会受到本机总内存（包括RAM以及SWAP区或分页文件）大小以及处理器寻址空间的限制。服务器管理员在配置虚拟机参数时，会根据实际内存设置-Xmx等参数信息，但经常忽略直接内存，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统的限制），从而导致动态扩展时出现OutOfMemoryError异常。


#### 2.2GC回收策略

>**2.2.1判断对象是否存活**

>***1.引用计数算法***

>给对象添加一个引用计数器，每当有一个地方引用它时，计数器值就加1，当引用失效时，计数器值就减1，任何时刻计数器都为0的对象就是不可能再被使用的。

>引用计数算法的实现简单，判定效率也很高，在大部分情况下它都是一个不错的选择，当Java语言并没有选择这种算法来进行垃圾回收，主要原因是它很难解决对象之间的相互循环引用问题

>***2.根搜索算法***

>Java和C#中都是采用根搜索算法来判定对象是否存活的。这种算法的基本思路是通过一系列名为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，就证明此对象是不可用的。在Java语言里，可作为GC 

>Roots的兑现包括下面几种：

>•	虚拟机栈（栈帧中的本地变量表）中引用的对象。

>•	方法区中的类静态属性引用的对象。

>•	方法区中的常量引用的对象。

>•	本地方法栈中JNI（Native方法）的引用对象。


>实际上，在根搜索算法中，要真正宣告一个对象死亡，至少要经历两次标记过程：如果对象在进行根搜索后发现没有与GC Roots相连接的引用链，那它会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize（）方法。当对象没有覆盖finalize（）方法，或finalize（）方法已经被虚拟机调用过，虚拟机将这两种情况都视为没有必要执行。如果该对象被判定为有必要执行finalize（）方法，那么这个对象将会被放置在一个名为F-Queue队列中，并在稍后由一条由虚拟机自动建立的、低优先级的Finalizer线程去执行finalize（）方法。finalize（）方法是对象逃脱死亡命运的最后一次机会（因为一个对象的finalize（）方法最多只会被系统自动调用一次），稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果要在finalize（）方法中成功拯救自己，只要在finalize（）方法中让该对象重引用链上的任何一个对象建立关联即可。而如果对象这时还没有关联到任何链上的引用，那它就会被回收掉。

>**2.2.2引用**

>***⑴强引用（StrongReference）***

>强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。  ps：强引用其实也就是我们平时A a = new A()这个意思。

>***⑵软引用（SoftReference）***

>如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存（下文给出示例）。

>软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。

>***⑶弱引用（WeakReference）***

>弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。

>弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。

>***⑷虚引用（PhantomReference）***

>“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。

>虚引用主要用来跟踪对象被垃圾回收器回收的活动。虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。

>程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。

	1.显式的把（强引用）对象置为null，会大大加大 垃圾回收执行频率。几乎只要我们给出建议，jvm就会回收。 
	2.对于软引用，如果不显式的置为null的话，和强引用差不多，垃圾回收不会执行。只会等到内存不足的时候才会执行。 
	3.对于弱引用，就算你不显式的把他置为null，垃圾回收也会立即执行。 
	4.虚引用，相当于null，不解释。 


>**2.2.3垃圾收集算法**

>***1.标记清除算法***

>标记—清除算法是最基础的收集算法，它分为“标记”和“清除”两个阶段：首先标记出所需回收的对象，在标记完成后统一回收掉所有被标记的对象，它的标记过程其实就是前面的根搜索算法中判定垃圾对象的标记过程。

>***缺点：***

>(1)标记和清除效率不高

>(2)标记清除后会产生大量不连续的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不触发另一次垃圾收集动作。


>***2.复制算法***

>将可用内存按照容量划分为大小相等的两块，每次只使用其中一块。当这一块内存用完后，将活着的对象复制到另一块上面，然后把已使用过的内存空间一次清理掉。

>现在商业虚拟机使用采用这种方法回收新生代，将内存分为**一块较大的Eden空间和两个较小的Survivor空间**，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活的对象一次性拷贝到另外一块Survivor空间上，最后清理掉Eden和刚才使用过的Survivor空间

>***优点与缺陷***

>优点：这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。

>缺陷：只是这种算法的代价是将内存缩小为原来的一半，代价过高。

>***3.标记整理算法***

>复制算法比较适合于新生代，在老年代中，对象存活率比较高，如果执行较多的复制操作，效率将会变低，所以老年代一般会选用其他算法，如标记—整理算法。该算法标记的过程与标记—清除算法中的标记过程一样，但对标记后出的垃圾对象的处理情况有所不同，它不是直接对可回收对象进行清理，而是让所有的对象都向一端移动，然后直接清理掉端边界以外的内存。

>***4.分代收集算法***

>当前商业虚拟机的垃圾收集都采用分代收集算法，此算法相较于前几种没有什么新的特征，主要思想为：根据对象存活周期的不同将内存划分为几块，一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适合的收集算法。

>***算法建议***

    适于“新生代”的算法建议 

    在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。

    适于“老年代”的算法建议 

    在老年代中，因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或“标记-整理”算法来进行回收。

>**2.2.4内存分配和回收策略**

>***Minor GC和Major GC区别***

>Minor GC（新生代GC）指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。

>Major GC/Full GC（老年代GC）指发生在老年代的GC,出现了Major GC,经常会伴随至少一次Minor GC（但非绝对）。Major GC速度一般比Minor GC慢10倍以上。

>**分配策略**

>1.对象优先在 Eden 分配

>2.大对象直接进入老年代

>>可以通过-XX:PretenureSizeThreshold设置超过多少大小的对象

>3.长期存活的对象将进入老年代

>>虚拟机给每个对象定义了一个对象年龄（Age）计数器。如果对象在Eden出生并经过第一次 Minor GC后仍然存活，并且能被Survivor 容纳的话，将被移动到 Survivor空间中，并且对象年龄设为1。对象在Survivor 区 每“熬过”一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就会晋升到老年代中。

>>可通过-XX:MaxTenuringThreshold来设置对象晋升老年代的年龄阀值。

>4.动态对象年龄判断

>>为了能够更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象年龄必须达到MaxTenuringThreshold规定值才能晋升老年代，如果在 Survivor 空间中相同年龄所有对象大小的总和大于Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到参数的规定值。

>5.空间分配担保

>>在发生 Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间。

>>5.1如果以上条件成立，那么 Minor GC可确保时安全的。

>>5.2若不成立，则虚拟机会查看HandlePromotionFailure参数设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小。 
如果大于，将尝试着进行一次Minor GC，尽管这次Minor GC是有风险的；
如果小于或者HandlePromotionFailure参数设置不允许“冒险”，此时改为进行一次 Full GC。


#### 2.3Java中对象的生命周期
#### 2.4JVM 内存区域 开线程影响哪块内存（内存分配）
#### 2.5JVM内存模型

>定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中读取变量这样的底层细节.

>Java内存模型规定了：***所有的变量都存储在主内存中。***

>每条线程还有自己的工作内存，线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取，赋值）都必须在工作内存中进行，而不能直接读写内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量。

	在内存模型中 
	1.使用volatile实现可见性，即在多线程时候，当一个线程修改参数，会通知其他线程将参数置为不可用，需要从内存中读取。
	2.要通过加锁（使用 synchronize 或 java.util.concurrent中的原子类）来保证原子性。
	3.使用volatile变量的第二个语义是禁止指令重排序优化：**普通变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。**

![Java 内存模型](./img/java_memory_model.png)

#### 2.6类加载机制

>类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载、验证、准备、解析、初始化、使用和卸载七个阶段。它们开始的顺序如下图所示：

![JVM class loader](./img/JVM_classLoader.png)

>其中类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也成为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。

#### 2.7类加载器与双亲委派模型

>**类加载器**

>(1)***Bootstrap ClassLoader*** : 将存放于<JAVA_HOME>\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如 rt.jar 名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用

>(2)***Extension ClassLoader*** : 将<JAVA_HOME>\lib\ext目录下的，或者被java.ext.dirs系统变量所指定的路径中的所有类库加载。开发者可以直接使用扩展类加载器。

>(3)***Application ClassLoader*** : 负责加载用户类路径(ClassPath)上所指定的类库,开发者可直接使用。

>**双亲委派模型**

![JVM 双亲委派机制](./img/JVM_parent_loader.png)

>工作过程：如果一个类加载器接收到了类加载的请求，它首先把这个请求委托给他的父类加载器去完成，每个层次的类加载器都是如此，因此所有的加载请求都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它在搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。

>好处：java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如类java.lang.Object，它存放在rt.jar中，无论哪个类加载器要加载这个类，最终都会委派给启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都是同一个类。相反，如果用户自己写了一个名为java.lang.Object的类，并放在程序的Classpath中，那系统中将会出现多个不同的Object类，java类型体系中最基础的行为也无法保证，应用程序也会变得一片混乱。

>>***双亲委派模型的系统实现***

	1.先检查是否已经被加载过

	2.若没有被加载过，则接着判断父加载器是否为空。
		2.1若不为空，则调用父类加载器的loadClass()方法。
		2.2若父加载器为空，则默认使用启动类加载器作为父加载器。
	
	3.如果父加载失败，则抛出ClassNotFoundException异常后，再调用自己的findClass()方法进行加载

###集合类
####HashMap实现原理

>通过数组+链表实现，通过**链地址法解决hash冲突**



####hashmap如何put数据（从hashmap源码角度讲解）？

	1.当key不为空时，获取对应的hash值和对应数组的位置
	2.判断key是否已经存在，如果存在 更新value值	不存在 新建节点放到map中

	``` public V put(K key, V value) {
        if (key == null)
            return putForNullKey(value); //null总是放在数组的第一个链表中
        int hash = hash(key.hashCode());
        int i = indexFor(hash, table.length);
        //遍历链表
        for (Entry<K,V> e = table[i]; e != null; e = e.next) {
            Object k;
            //如果key在链表中已存在，则替换为新value
            if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
                V oldValue = e.value;
                e.value = value;
                e.recordAccess(this);
                return oldValue;
            }
        }
        modCount++;
        addEntry(hash, key, value, i);
        return null;
    }
 
	void addEntry(int hash, K key, V value, int bucketIndex) {
	    Entry<K,V> e = table[bucketIndex];
	    table[bucketIndex] = new Entry<K,V>(hash, key, value, e); //参数e, 是Entry.next
	    //如果size超过threshold，则扩充table大小。再散列
	    if (size++ >= threshold)
	            resize(2 * table.length);
	}```

	

	```
	public V get(Object key) {
        if (key == null)
            return getForNullKey();
        int hash = hash(key.hashCode());
        //先定位到数组元素，再遍历该元素处的链表
        for (Entry<K,V> e = table[indexFor(hash, table.length)];
             e != null;
             e = e.next) {
            Object k;
            if (e.hash == hash && ((k = e.key) == key || key.equals(k)))
                return e.value;
        }
        return null;
	}```

####ConcurrentHashMap 的实现原理
####集合 Set实现 Hash 怎么防止碰撞
####TreeMap
####HashSet与HashMap怎么判断集合元素重复
###抽象类和接口的区别
###进程调度
###Java注解
###String buffer 与String builder 的区别
###Java四种引用
####强引用置为null，会不会被回收
###String 为什么要设计成不可变的

###Object类的equal 和hashcode 方法重写，为什么？</br>

>1、 为什么要重载equal方法？

>答案：因为Object的equal方法默认是两个对象的引用的比较，意思就是指向同一内存,地址则相等，否则不相等；如果你现在需要利用对象里面的值来判断是否相等，则重载equal方法。

>2、 为什么重载hashCode方法？

>答案：一般的地方不需要重载hashCode，只有当类需要放在HashTable、HashMap、HashSet等等hash结构的集合时才会重载hashCode，那么为什么要重载hashCode呢？就HashMap来说，好比HashMap就是一个大内存块，里面有很多小内存块，小内存块里面是一系列的对象，可以利用hashCode来查找小内存块hashCode%size(小内存块数量)，所以当equal相等时，hashCode必须相等，而且如果是object对象，必须重载hashCode和equal方法。

>3、 为什么equals()相等，hashCode就一定要相等，而hashCode相等，却不要求equals相等?

>答案：1、因为是按照hashCode来访问小内存块，所以hashCode必须相等。

>2、HashMap获取一个对象是比较key的hashCode相等和equal为true。之所以hashCode相等，却可以equal不等，就比如ObjectA和ObjectB他们都有属性name，那么hashCode都以name计算，所以hashCode一样，但是两个对象属于不同类型，所以equal为false。

>4、 为什么需要hashCode?

>1、 通过hashCode可以很快的查到小内存块。
>
>2、通过hashCode比较比equal方法快，当get时先比较hashCode，如果hashCode不同，直接返回false。


##Android
###LruCache原理

>Lru的全称是Least Recently Used ，近期最少使用的！实现原理：把近期最少使用的数据从缓存中移除，保留使用最频繁的数据

>Lru算法的实现就是通过LinkedHashMap来实现的。LinkedHashMap继承于HashMap，它使用了一个双向链表来存储Map中的Entry顺序关系，这种顺序有两种，一种是LRU顺序，一种是插入顺序，这可以由其构造函数public LinkedHashMap(int initialCapacity,float loadFactor, boolean accessOrder)指定。所以，对于get、put、remove等操作，LinkedHashMap除了要做HashMap做的事情，还做些调整Entry顺序链表的工作。LruCache中将LinkedHashMap的顺序设置为LRU顺序来实现LRU缓存，每次调用get(也就是从内存缓存中取图片)，则将该对象移到链表的尾端。调用put插入新的对象也是存储在链表尾端，这样当内存缓存达到设定的最大值时，将链表头部的对象（近期最少用到的）移除。

###Glide原理

####glide 使用什么缓存

>Glide的缓存机制分为两级，第一级是***内存缓存***，然后第二级是***硬盘缓存***。缓存的过程首先是在内存中缓存，然后将加载的图片资源缓存到硬盘，这样就可以在随后的再次加载中使用缓存了，Glide使用缓存时候首先要检查内存这一层级是否缓存了相应的缓存，如果有，则直接使用，如果没有，则深入到硬盘缓存中检查是否有，如果有，则加载之，如果到这一步骤还没有，那么就只能作为一个全新的资源加载了。

####Glide 内存缓存如何控制大小
###模块化的好处、原因
###统计启动时长、标准
###如何保障应用的稳定性


###ThreadLocal原理

>在ThreadLocal类中有一个静态内部类ThreadLocalMap(其类似于Map)，用键值对的形式存储每一个线程的变量副本，ThreadLocalMap中元素的key为当前ThreadLocal对象，而value对应线程的变量副本，每个线程可能存在多个ThreadLocal。

	```
	public T get() {
	    Thread t = Thread.currentThread();//当前线程
	    ThreadLocalMap map = getMap(t);//获取当前线程对应的ThreadLocalMap
	    if (map != null) {
	        ThreadLocalMap.Entry e = map.getEntry(this);//获取对应ThreadLocal的变量值
	        if (e != null) {
	            @SuppressWarnings("unchecked")
	            T result = (T)e.value;
	            return result;
	        }
	    }
	    return setInitialValue();//若当前线程还未创建ThreadLocalMap，则返回调用此方法并在其中调用createMap方法进行创建并返回初始值。
	}
	//设置变量的值
	public void set(T value) {
	   Thread t = Thread.currentThread();
	   ThreadLocalMap map = getMap(t);
	   if (map != null)
	       map.set(this, value);
	   else
	       createMap(t, value);
	}
	private T setInitialValue() {
	   T value = initialValue();
	   Thread t = Thread.currentThread();
	   ThreadLocalMap map = getMap(t);
	   if (map != null)
	       map.set(this, value);
	   else
	       createMap(t, value);
	   return value;
	}
	/**
	为当前线程创建一个ThreadLocalMap的threadlocals,并将第一个值存入到当前map中
	@param t the current thread
	@param firstValue value for the initial entry of the map
	*/
	void createMap(Thread t, T firstValue) {
	    t.threadLocals = new ThreadLocalMap(this, firstValue);
	}
	//删除当前线程中ThreadLocalMap对应的ThreadLocal
	public void remove() {
	       ThreadLocalMap m = getMap(Thread.currentThread());
	       if (m != null)
	           m.remove(this);
	}```

>***内存泄漏***

>由于ThreadLocalMap的生命周期跟Thread一样长，如果都没有手动删除对应key，都会导致内存泄漏，但是使用弱引用可以多一层保障：弱引用ThreadLocal不会内存泄漏，对应的value在下一次ThreadLocalMap调用set,get,remove的时候会被清除。所以在使用ThreadLocal当key使用完成的时候需要remove掉。

###热修复、插件化

###性能优化
####保证应用不卡顿
####Android相关优化（如内存优化、网络优化、布局优化、电量优化、业务优化）

###SP是进程同步的吗?有什么方法做到同步

>SP中2.3以下默认实现同步，但是在2.3以后需要设置参数***MODE_MULTI_PROCESS***，这样不同进程加载可以实现同步

###介绍下SurfView

###BroadcastReceiver，LocalBroadcastReceiver 区别

>1.其他App可能发出和本App需要类型相同的广播，导致App不断接收广播并处理

>2.其他App接收到本App发送的广播

>***解决方案：***
	
	1.将全局广播设置成局部广播
	（1）注册广播时将exported设置为false
	（2）增加权限设置
	（3）使用intent.setPackage去指定接收者的包名
	2.使用LocalBroadcastManager类


###Bundle 机制

###Handler 机制
>***3.6.1相关概念***


>Message
>
>定义：消息，理解为线程间通讯的数据单元（Handler接受和处理的消息对象。）
>
>Message Queue
>
>消息队列，用于存放Handler发送的消息，先进先出
>
>Handler

>是Message的主要处理者，负责将Message添加到队列或者处理Looper分派过来的Message

>Looper 

>扮演Message Queue和Handler之间桥梁的角色，循环取出Message Queue的Message,将取出的Message交给对应的Handler


>***3.6.2方法***


>Handler
>
>提供sendMessage方法，将消息放置到队列中 

>提供handleMessage方法，定义个各种消息的处理方式；

>Looper

>Looper.prepare()：实例化Looper对象；为当前线程生成一个消息队列；

>Looper.loop() ：循环从消息队列中获取消息，交给Handler处理；此时线程处于无限循环中，不停的从MessageQueue中获取Message 消息 ；如果没有消息就阻塞
> 
>MessageQueue
>
>提供enqueueMessage 方法，将消息根据时间放置到队列中；
>
>提供next方法，从队列中获取消息，没有消息的时候阻塞；

	Handler工作流程解释
	异步通信传递机制步骤主要包括异步通信的准备、消息发送、消息循环和消息处理
	1.	异步通信的准备
	包括Looper对象的创建&实例化、MessageQueue队列的创建和Handler的实例化
	2.	消息发送
	Handler将消息发送到消息队列中
	3.	消息循环
	Looper执行Looper.loop()进入消息循环，在这个循环过程中，不断从该Message Queue取出消息，并将取出的消息派发给创建该消息的Handler
	4.	消息处理
	调用该Handler的dispatchMessage(msg)方法，即回调handleMessage(msg)处理消息

>***3.6.3Looper***
>
>Looper主要是prepare()和loop()两个方法.

>在prepare()判断已经创建MessageQueue，未创建则调用Looper构造方法创建一个MessageQueue。

>在loop()中，进行无限循环去取消息，若无消息则阻塞，若取到消息，则msg.target.dispatchMessage(msg);把消息交给msg的target的dispatchMessage方法去处理。

>***3.6.4Handler***
>
>Handler主要完成：

>1.在主线程中发消息给MessageQueue

>使用Handler之前，会初始化一个Handler实例，在创建实例时，会通过Loop.myLooper()获取当前线程的Looper对象，不存在则抛出异常。
Handler想MessageQueue发送消息可以发送post和send两种，相比send方法，post最大不同在于更新操作可以直接在重写run方法定义，在发送消息最终都会调用queue.enqueueMessage()将消息放入对流

>2.处理Looper派发来的消息：dispatchMessage();

>调用send是的handlerMessage回调方法或者post时的msg回调


>***3.6.5MessageQueue***
>
>MessageQueue包含enqueueMessage入队操作和next()出队操作

>***3.6.6其他***
>
>一个Thread（线程）只能有一个Looper，可以有多个Handler
>
>一个Looper可以绑定多个Handler；
>
>一个Handler只能绑定一个Looper；

###Android事件分发机制



###App启动流程，从点击桌面开始


###Android 的大体架构图

![APK构建过程](./img/AndroidSystem.jpg)

> Android的系统架构采用了分层架构的思想，如上图所示。从上层到底层共包括四层，分别是应用程序程序层、应用框架层、系统库和Android运行时和Linux内核。

>一 应用程序层


>该层提供一些核心应用程序包，例如电子邮件、短信、日历、地图、浏览器和联系人管理等。同时，开发者可以利用Java语言设计和编写属于自己的应用程序，而这些程序与那些核心应用程序彼此平等、友好共处。
 
>二 应用程序框架层
 
>该层是Android应用开发的基础，开发人员大部分情况是在和她打交道。应用程序框架层包括活动管理器、窗口管理器、内容提供者、视图系统、包管理器、电话管理器、资源管理器、位置管理器、通知管理器和XMPP服务十个部分。在Android平台上，开发人员可以完全访问核心应用程序所使用的API框架。并且，任何一个应用程序都可以发布自身的功能模块，而其他应用程序则可以使用这些已发布的功能模块。基于这样的重用机制，用户就可以方便地替换平台本身的各种应用程序组件。
 
>三 系统库和Android运行时

>系统库包括九个子系统，分别是图层管理、媒体库、SQLite、OpenGLEState、FreeType、WebKit、SGL、SSL和libc。Android运行时包括核心库和Dalvik虚拟机，前者既兼容了大多数Java语言所需要调用的功能函数，又包括了Android的核心库，比如android.os、android.net、android.media等等。后者是一种基于寄存器的java虚拟机，Dalvik虚拟机主要是完成对生命周期的管理、堆栈的管理、线程的管理、安全和异常的管理以及垃圾回收等重要功能。

>四 Linux内核

>Android核心系统服务依赖于Linux2.6内核，如安全性、内存管理、进程管理、网络协议栈和驱动模型。Linux内核也是作为硬件与软件栈的抽象层。驱动：显示驱动、摄像头驱动、键盘驱动、WiFi驱动、Audio驱动、flash内存驱动、Binder（IPC）驱动、电源管理等。

###点击 Android Studio 的 build 按钮后发生了什么
![APK构建过程](./img/apkbuild.png)

>**1.AAPT(Android Asset Packaging Tool)工具会打包应用中的资源文件**
>
>如AndroidManifest.xml、layout布局中的xml等，并将xml文件编译为二进制形式，当然assets文件夹中的文件不会被编译，图片及raw文件夹中的资源也会保持原来的形态，需要注意的是raw文件夹中的资源也会生成资源id。AAPT编译完成之后会生成R.java文件。
>**2.AIDL工具会将所有的aidl接口转化为java接口。**
>
>**3.所有的java代码，包括R.java与aidl文件都会被Java编译器编译成.class文件。**
>
>**4.Dex工具会将上述产生的.class文件及第三库及其他.class文件编译成.dex文件（dex文件是Dalvik虚拟机可以执行的格式），dex文件最终会被打包进APK文件。**
>
>**5.ApkBuilder工具会将编译过的资源及未编译过的资源（如图片等）以及.dex文件打包成APK文件。**
>
>**6.通过Jarsigner工具，对上面的apk进行debug或release签名**
>
>生成APK文件后，需要对其签名才可安装到设备，平时测试时会使用debug keystore，当正式发布应用时必须使用release版的keystore对应用进行签名。
>
>**7. 通过zipalign工具，将签名后的apk进行对齐处理。**
>
>调用buildtoolszipalign，对签名后的apk文件进行对齐处理，使apk中所有资源文件距离文件起始偏移为4字节的整数倍，从而在通过内存映射访问apk文件时会更快。同时也减少了在设备上运行时的内存消耗。这样我们的最终apk就生成完毕了。

###一个应用程序安装到手机上时发生了什么
###对 Dalvik、ART 虚拟机有基本的了解
###Android 上的 Inter-Process-Communication 跨进程通信时如何工作的


###App 是如何沙箱化，为什么要这么做；

>Android“沙箱”的本质是为了实现不同应用程序和进程之间的互相隔离，即在默认情况 下，应用程序没有权限访问系统资源或其它应用程序的资源。每个APP和系统进程都被分配唯一并且固定的User Id，这个uid与内核层进程的uid对应。每个APP在各自独立的Dalvik虚拟机中运行，拥有独立的地址空间和资源。运行于Dalvik虚拟机中的 进程必须依托内核层Linux进程而存在，因此Android使用Dalvik虚拟机和Linux的文件访问控制来实现沙箱机制，任何应用程序如果想要访 问系统资源或者其它应用程序的资源必须在自己的manifest文件中进行声明权限或者共享uid。
 
>安装在设备中的每一个apk文件，Android给每个APK进程分配一个单独的用户空间,其manifest中的userid就是对应一个Linux 用户都会被分配到一个属于自己的统一的Linux用户ID，并且为它创建一个沙箱，以防止影响其他应用程序（或者其他应用程序影响它）。用户ID 在应用程序安装到设备中时被分配，并且在这个设备中保持它的永久性。
 
>通过Shared User id,拥有同一个User id的多个APK可以配置成运行在同一个进程中.所以默认就是可以互相访问任意数据. 也可以配置成运行成不同的进程, 同时可以访问其他APK的数据目录下的数据库和文件.就像访问本程序的数据一样.

###动态权限适配方案，权限组的概念

>在***M版本(23)***之前，应用App需要用到什么权限只需要在AndroidManifest.xml配置文件中增加相对应权限的配置，然后在App中就可以随便无限制的使用这些权限来访问用户的设备了。由于这种权限的漏洞，导致了大量的用户信息的泄露。所以在M版本上，Android官方团队重新修改了这个权限的申请方式。在新的权限模式之下，用户将能够根据自己的实际需要在运行时中对各项权限进行审核，且随时关闭其中的部分权限。

>在Android6.0之前，所有的权限都是安装时权限，即安装时就可获取，在6.0开始讲权限做了区分，运行时权限，同时将权限分组，同一权限组的权限，只要获取一个权限，同一权限组的其他权限也都会获得。

###进程和 Application 的生命周期；

###RecycleView的使用，原理,recycleview listview 的区别,性能


###listview图片加载错乱的原理和解决方案

>**原理**

	1.listview中item加载的时候采用复用机制，当item移出屏幕时会再复用

	2.图片的异步加载

>**解决方案**

	为imageView设置一个唯一的tag（比如url），当图片加载完成的时候比较imageview的tag是否对应这张图片，等于则加载

###MVP模式
###RxJava

###网络请求缓存处理，okhttp如何处理网络缓存的

>1.使用文件进行缓存

>当请求到数据后，将数据缓存到文件中，下次请求的时候读取文件的上次修改时间，当大于一定的时间则重新请求，小于时间和读取缓存中的数据

>2.okhttp网络缓存

###图片加载库相关，bitmap如何处理大图，如一张30M的大图，如何预防OOM
###进程保活
###广播（动态注册和静态注册区别，有序广播和标准广播）
###service生命周期
###多线程
####多线程（关于AsyncTask缺陷引发的思考）
####Android系统为什么会设计ContentProvider，进程共享和线程安全问题
####Android线程有没有上限，然后提到线程池的上限
###数据库数据迁移问题
###进程间通信的方式
###计算一个view的嵌套层级
###多线程断点续传原理
###activity栈
###断点续传的实现
###Android进程分类
###ANR的原因
###Activity与Fragment之间生命周期比较
####fragment 各种情况下的生命周期
####横竖屏切换的时候，Activity 各种情况下的生命周期
####Activity 上有 Dialog 的时候按 home 键时的生命周期
####前台切换到后台，然后再回到前台，Activity生命周期回调方法。弹出Dialog，生命值周期回调方法
###广播的使用场景
###Oom 是否可以try catch
###AlertDialog,popupWindow,Activity区别
###Application 和 Activity 的 context 对象的区别
###序列化的作用，以及 Android 两种序列化的区别，Android为什么引入Parcelable，简化Parcelable的使用
###ANR怎么分析解决
###AIDL机制</br>
###AsyncTask机制</br>
###如何取消AsyncTask</br>


##计算机网络
###Https

>***1.起源***

>因为http请求中存在不验证通信方身份、明文传输、中间人攻击这些问题，很难保证web安全，于是出现了HTTPS

>http+加密处理+身份认证+完整性保护=HTTPS

>Https并非应用层的一种新协议，只是http通信接口部分用SSl和TLS协议代替，通常,HTTP直接和TCP通信。当使用SSL时,则演变成先和SSL通信,再由SSL和TCP通信

>***2.TLS/SSL协议工作原理***

>TLS/SSL的功能实现主要依赖于三类基本算法：散列函数 Hash（信息完整性校验）、对称加密(信息加密)和非对称加密(身份验证)，***其利用非对称加密实现身份认证和密钥协商，对称加密算法采用协商的密钥对数据加密，基于散列函数验证信息的完整性。***

![https ssl协议工作原理](./img/https_ssl.gif)

>****散列函数Hash****

>>常见的有 MD5、SHA1、SHA256，该类函数特点是函数单向不可逆、对输入非常敏感、输出长度固定，针对数据的任何修改都会改变散列函数的结果，用于防止信息篡改并验证数据的完整性;

>>在信息传输过程中，散列函数不能单独实现信息防篡改，因为明文传输，中间人可以修改信息之后重新计算信息摘要，因此需要对传输的信息以及信息摘要进行加密;

>****称加密****

>>常见的有 AES-CBC、DES、3DES、AES-GCM等，相同的密钥可以用于信息的加密和解密，掌握密钥才能获取信息，能够防止信息窃听，通信方式是1对1;

>>对称加密的优势是信息传输1对1，需要共享相同的密码，密码的安全是保证信息安全的基础，服务器和 N 个客户端通信，需要维持 N 个密码记录，且缺少修改密码的机制;

>****非对称加密****

>>即常见的 RSA 算法，还包括 ECC、DH 等算法，算法特点是，密钥成对出现，一般称为公钥(公开)和私钥(保密)，公钥加密的信息只能私钥解开，私钥加密的信息只能公钥解开。因此掌握公钥的不同客户端之间不能互相解密信息，只能和掌握私钥的服务器进行加密通信，服务器可以实现1对多的通信，客户端也可以用来验证掌握私钥的服务器身份。

>>非对称加密的特点是信息传输1对多，服务器只需要维持一个私钥就能够和多个客户端进行加密通信，但服务器发出的信息能够被所有的客户端解密，且该算法的计算复杂，加密速度慢。

>结合三类算法的特点，TLS的基本工作方式是，客户端使用非对称加密与服务器进行通信，实现身份验证并协商对称加密使用的密钥，然后对称加密算法采用协商密钥对信息以及信息摘要进行加密通信，不同的节点之间采用的对称密钥不同，从而可以保证信息只能通信双方获取。

>***TLS/SSL握手过程***

![TLS/SSL握手过程](./img/ssl.png)

>****第一次握手 client_hello****

>客户端发起请求，以明文传输请求信息，包含版本信息，加密套件候选列表，压缩算法候选列表，随机数，扩展字段等信息，相关信息如下：

>>支持的最高TSL协议版本version，从低到高依次 SSLv2 SSLv3 TLSv1 TLSv1.1 TLSv1.2，当前基本不再使用低于 TLSv1 的版本;

>>客户端支持的加密套件 cipher suites 列表， 每个加密套件对应前面 TLS 原理中的四个功能的组合：认证算法 Au (身份验证)、密钥交换算法 KeyExchange(密钥协商)、对称加密算法 Enc (信息加密)和信息摘要 Mac(完整性校验);

>>支持的压缩算法 compression methods 列表，用于后续的信息压缩传输;

>>随机数 random_C，用于后续的密钥的生成;

>>扩展字段 extensions，支持协议与算法的相关参数以及其它辅助信息等，常见的 SNI 就属于扩展字段，后续单独讨论该字段作用。

>****第二次握手 server_hello+server_certificate+sever_hello_done****

>>(a) server_hello, 服务端返回协商的信息结果，包括选择使用的协议版本 version，选择的加密套件 cipher suite，选择的压缩算法 compression method、随机数 random_S 等，其中随机数用于后续的密钥协商;

>>(b)server_certificates, 服务器端配置对应的证书链，用于身份验证与密钥交换;

>>(c) server_hello_done，通知客户端 server_hello 信息发送结束;

>****证书校验****

>客户端验证证书的合法性，如果验证通过才会进行后续通信，否则根据错误情况不同做出提示和操作，合法性验证包括如下：

>>证书链的可信性 trusted certificate path

>>证书是否吊销 revocation，有两类方式离线 CRL 与在线 OCSP，不同的客户端行为会不同;

>>有效期 expiry date，证书是否在有效时间范围;

>>域名 domain，核查证书域名是否与当前的访问域名匹配，匹配规则后续分析;

>****第三次握手 client_key_exchange+change_cipher_spec+encrypted_handshake_message****

>>(a) client_key_exchange，合法性验证通过之后，客户端计算产生随机数字 Pre-master，并用证书公钥加密，发送给服务器;

>>(b) 此时客户端已经获取全部的计算协商密钥需要的信息：两个明文随机数 random_C 和 random_S 与自己计算产生的 Pre-master，计算得到协商密钥;

>>enc_key=Fuc(random_C, random_S, Pre-Master)

>>(c) change_cipher_spec，客户端通知服务器后续的通信都采用协商的通信密钥和加密算法进行加密通信;

>>(d) encrypted_handshake_message，结合之前所有通信参数的 hash 值与其它相关信息生成一段数据，采用协商密钥 session secret 与算法进行加密，然后发送给服务器用于数据与握手验证;

>****第四次握手 change_cipher_spec+encrypted_handshake_message****

>>(a) 服务器用私钥解密加密的 Pre-master 数据，基于之前交换的两个明文随机数 random_C 和 random_S，计算得到协商密钥:enc_key=Fuc(random_C, random_S, Pre-Master);

>>(b) 计算之前所有接收信息的 hash 值，然后解密客户端发送的 encrypted_handshake_message，验证数据和密钥正确性;

>>(c) change_cipher_spec, 验证通过之后，服务器同样发送 change_cipher_spec 以告知客户端后续的通信都采用协商的密钥与算法进行加密通信;

>>(d) encrypted_handshake_message, 服务器也结合所有当前的通信参数信息生成一段数据并采用协商密钥 session secret 与算法加密并发送到客户端;

>***一次https请求一共进行了七次握手 ssl4次加上http3次***

####如何验证证书的合法性
####哪里用了非对称加密
####Https请求慢的解决办法
* DNS，携带数据，直接访问IP


###TCP与UDP区别与应用（三次握手和四次挥手）涉及到部分细节（如client如何确定自己发送的消息被server收到） 

##算法
###排序，快速排序的实现、堆排序实现
###B树、B+树的介绍
###图：有向无环图的解释
###二叉树 深度遍历与广度遍历
###判断环（猜测应该是链表环）
###链表反转
###x个苹果，一天只能吃一个、两个、或者三个，问多少天可以吃完
###二叉树，给出根节点和目标节点，找出从根节点到目标节点的路径
###一个无序，不重复数组，输出N个元素，使得N个元素的和相加为M，给出时间复杂度、空间复杂度。手写算法
###string to integer</br>
###合并多个单有序链表（假设都是递增的）</br>
###两个不重复的数组集合中，求共同的元素


##设计模式
###适配器模式，装饰者模式，外观模式的异同
###生产者模式
###观察者模式

##加密技术